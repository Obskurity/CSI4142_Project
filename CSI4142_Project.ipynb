{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Staging\n",
    "### Extract, Transform, Load (ETL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J-vg3IuRsoL5"
   },
   "source": [
    "**Create Data Frame for Facility Locations in Ontario**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 373,
   "metadata": {
    "id": "u4Th7jCNRxVU"
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract Facility Location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "id": "Jt1MCF2QVjvS",
    "outputId": "9a7208eb-ac3f-454a-fc1a-8ad8d2c3b3cb"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Arthur\\AppData\\Local\\Temp\\ipykernel_13944\\371614087.py:3: DtypeWarning: Columns (17,18) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv('./ODRSF_v1.0.csv', encoding='cp1252')\n"
     ]
    }
   ],
   "source": [
    "# read file containing information about recreation centre locations and types\n",
    "# facility location dataframe\n",
    "df = pd.read_csv('./ODRSF_v1.0.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform Facility Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {
    "id": "AF4xSiyDWVPB"
   },
   "outputs": [],
   "source": [
    "# Remove unneeded columns\n",
    "df = df.drop(columns = ['Index', 'Facility_Name', 'Source_Facility_Type', 'Provider', 'City', 'Source_Format_Address', 'CSD_UID', 'PR_UID', 'Latitude', 'Longitude'])\n",
    "\n",
    "# Remove unit since almost all values are null\n",
    "df = df.drop(columns = ['Unit'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "id": "_1CiZM8ferMW"
   },
   "outputs": [],
   "source": [
    "#Replace empty values of street_no with -1\n",
    "df.loc[df['Street_No'] == '..', 'Street_No'] = '-1'\n",
    "\n",
    "# Replace rest of street strings with an empty value\n",
    "df.loc[df['Street_Name'] == '..', 'Street_Name'] = ''\n",
    "df.loc[df['Street_Type'] == '..', 'Street_Type'] = ''\n",
    "df.loc[df['Street_Direction'] == '..', 'Street_Direction'] = ''\n",
    "df.loc[df['Street_Direction'] == '..', 'Street_Direction'] = ''\n",
    "df.loc[df['Postal_Code'] == '..', 'Postal_Code'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "id": "jouxryv1k50D"
   },
   "outputs": [],
   "source": [
    "#convert street_no to integer\n",
    "df['Street_No'] = df['Street_No'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "id": "djTDyVRUk7ps"
   },
   "outputs": [],
   "source": [
    "# Captialize all province/territory column\n",
    "df['Prov_Terr'] = df['Prov_Terr'].str.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "id": "1AywaMwzymy2"
   },
   "outputs": [],
   "source": [
    "# remove all non ontario provinces\n",
    "df = df[df['Prov_Terr'] == 'ON']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace sudbury areas with just sudbury\n",
    "\n",
    "# Remove unnecessary information after comma in geo_name so processing can be easier\n",
    "df['CSD_Name'] = df['CSD_Name'].str.split(',').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "id": "kGYRd7NECJy9"
   },
   "outputs": [],
   "source": [
    "#unique_cities = df['City'].unique()\n",
    "unique_cities = df['CSD_Name'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_rename_dict = {\n",
    "    'CSD_Name': 'City',\n",
    "    'ODRSF_facility_type': 'FacilityType',\n",
    "}\n",
    "\n",
    "df = df.rename(columns=column_rename_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating Surrogate Key for Location Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Facility ID'] = range(1,len(df)+1)\n",
    "\n",
    "df = df.reindex(columns=['Facility ID'] + list([c for c in df.columns if c!= 'Facility ID']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l4WjI9uWaBE1"
   },
   "source": [
    "**Create Dataframe for City Demographics in Ontario**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "id": "B694hG3tEyYt"
   },
   "outputs": [],
   "source": [
    "demographic_df = pd.read_csv('./Ontario_Demographics.csv', encoding='cp1252')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "id": "DXG6weeKE0IQ"
   },
   "outputs": [],
   "source": [
    "demographic_df = demographic_df.drop(columns = ['CENSUS_YEAR', 'DGUID', 'ALT_GEO_CODE', 'GEO_LEVEL', 'TNR_SF', 'TNR_LF', 'DATA_QUALITY_FLAG','SYMBOL', 'CHARACTERISTIC_ID', 'CHARACTERISTIC_NOTE', 'C2_COUNT_MEN+', 'C3_COUNT_WOMEN+', 'C10_RATE_TOTAL', 'C11_RATE_MEN+', 'C12_RATE_WOMEN+', 'SYMBOL.1','SYMBOL.2','SYMBOL.3','SYMBOL.4','SYMBOL.5'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "id": "06JmSp--G_F9"
   },
   "outputs": [],
   "source": [
    "# Remove unnecessary information after comma in geo_name so processing can be easier\n",
    "demographic_df['GEO_NAME'] = demographic_df['GEO_NAME'].str.split(',').str[0]\n",
    "\n",
    "# only keep rows where the city is both in the demographic dataframe and the facility location dataframe\n",
    "demographic_df = demographic_df[demographic_df['GEO_NAME'].isin(unique_cities)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "id": "e4kFAwyFPBZ-"
   },
   "outputs": [],
   "source": [
    "#get starting and ending index of rows that contain age information about the city\n",
    "age_indexes = demographic_df[demographic_df['CHARACTERISTIC_NAME'].str.contains('Total - Age groups of the population - 100% data|100 years and over')].index\n",
    "\n",
    "#get starting and ending index of rows that contain ethnicity information about the city\n",
    "ethnicity_indexes = demographic_df[demographic_df['CHARACTERISTIC_NAME'].str.contains('Total visible minority population|Total - Ethnic or cultural origin for the population in private households - 25% sample data')].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "id": "g0bFTYZuT6An"
   },
   "outputs": [],
   "source": [
    "selected_age_dfs = []\n",
    "selected_ethnicity_dfs = []\n",
    "\n",
    "# store only data in dataframe from start and end indexes\n",
    "for i in range(0, len(age_indexes), 2):\n",
    "    age_df = demographic_df[age_indexes[i] + 1: age_indexes[i + 1] + 1]\n",
    "    ethnicity_df = demographic_df[ethnicity_indexes[i] + 1: ethnicity_indexes[i + 1]]\n",
    "    selected_age_dfs.append(age_df)\n",
    "    selected_ethnicity_dfs.append(ethnicity_df)\n",
    "\n",
    "#resulting dataframes \n",
    "result_age_df = pd.concat(selected_age_dfs, ignore_index=True)\n",
    "result_ethnicity_df = pd.concat(selected_ethnicity_dfs, ignore_index=True)\n",
    "\n",
    "# since some 'cities' have multiple occurences(i.e, different regions, we will need to keep each of their unique values.)\n",
    "# To make the ETL process easier, we want to make it so each city in their respective data occurs only once\n",
    "prev_city = None\n",
    "for index, row in result_age_df.iterrows():\n",
    "    # Check if current city is different from previous city\n",
    "    if row['GEO_NAME'] == prev_city:\n",
    "        # Drop the row if the city is the same as the previous one\n",
    "        result_age_df.at[index, 'GEO_NAME'] = ''\n",
    "    else:\n",
    "        # Update previous city\n",
    "        prev_city = row['GEO_NAME']\n",
    "\n",
    "# special cases where these CSDs are right after each other so the for loop above does not work\n",
    "result_age_df.at[4875, 'GEO_NAME'] = 'Nipissing'\n",
    "result_age_df.at[5200, 'GEO_NAME'] = 'Parry Sound'\n",
    "\n",
    "prev_city = None\n",
    "for index, row in result_ethnicity_df.iterrows():\n",
    "    # Check if current city is different from previous city\n",
    "    if row['GEO_NAME'] == prev_city:\n",
    "        # Drop the row if the city is the same as the previous one\n",
    "        result_ethnicity_df.at[index, 'GEO_NAME'] = ''\n",
    "    else:\n",
    "        # Update previous city\n",
    "        prev_city = row['GEO_NAME']    \n",
    "\n",
    "# special cases where these CSDs are right after each other so the for loop above does not work\n",
    "result_ethnicity_df.at[2535, 'GEO_NAME'] = 'Nipissing'\n",
    "result_ethnicity_df.at[2703, 'GEO_NAME'] = 'Parry Sound'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 389,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set empty values/null to 0\n",
    "result_age_df.fillna({'C1_COUNT_TOTAL': 0}, inplace=True)\n",
    "# check for null\n",
    "result_age_df['C1_COUNT_TOTAL'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set empty values/null to 0\n",
    "result_ethnicity_df.fillna({'C1_COUNT_TOTAL': 0}, inplace=True)\n",
    "# check for null\n",
    "result_ethnicity_df['C1_COUNT_TOTAL'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all cities from the dataframe(cities are the same from the age dataframe and tehnicity dataframe)\n",
    "cities = result_age_df[result_age_df['GEO_NAME'] != '']['GEO_NAME']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose Age Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique age ranges - will be used as the new column in the new dataframe\n",
    "ages = result_age_df['CHARACTERISTIC_NAME'].unique()\n",
    "\n",
    "age_df = pd.DataFrame(columns=ages)\n",
    "\n",
    "# add new column for city\n",
    "age_df.insert(loc=0, column='City', value='')\n",
    "\n",
    "# remove whitespace from columns\n",
    "age_df = age_df.rename(columns=lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate first column cities with all city variables\n",
    "age_df['City'] = cities\n",
    "age_count = result_age_df['C1_COUNT_TOTAL'].tolist()\n",
    "\n",
    "for i in range(len(cities)):\n",
    "    if i == 0:\n",
    "        age_df.iloc[i, 1:] = age_count[:25]\n",
    "    else:\n",
    "        age_df.iloc[i, 1:] = age_count[i * 25 : (i + 1) * 25]\n",
    "        \n",
    "for column in age_df.columns[1:]:\n",
    "    age_df[column] = age_df[column].astype(int)\n",
    "\n",
    "# Sum duplicate rows since we consider regions of a City as the same City, and sort data by City\n",
    "age_df = age_df.groupby('City').sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# redundant data that can be dropped\n",
    "age_df = age_df.drop(columns = ['0 to 14 years', '15 to 64 years','65 years and over'])\n",
    "\n",
    "# NOTE: We decided to not bucketisize the columns since most of the data errs on one side of the spectrum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if this is needed since we can easily match through the natural keys\n",
    "age_df.insert(0, 'Age City ID', '')\n",
    "age_df['Age City ID'] = ['A' + str(x) for x in range(1, len(age_df) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transpose Ethnicity Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unique ethnicities\n",
    "ethnicities = result_ethnicity_df['CHARACTERISTIC_NAME'].unique()\n",
    "\n",
    "ethnicity_df = pd.DataFrame(columns=ethnicities)\n",
    "\n",
    "ethnicity_df.insert(loc=0, column='City', value='')\n",
    "\n",
    "# remove whitespace from columns\n",
    "ethnicity_df = ethnicity_df.rename(columns=lambda x: x.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Populate first column with all cities\n",
    "ethnicity_df['City'] = cities\n",
    "ethnicity_count = result_ethnicity_df['C1_COUNT_TOTAL'].tolist()\n",
    "\n",
    "# Populate column data\n",
    "k = 0\n",
    "for i in range(len(cities)):\n",
    "    if i == 0:\n",
    "        ethnicity_df.iloc[i, 1:] = ethnicity_count[:13]\n",
    "    else:\n",
    "        ethnicity_df.iloc[i, 1:] = ethnicity_count[i * 13 : (i + 1) * 13]\n",
    "\n",
    "#change type from float to int\n",
    "for column in ethnicity_df.columns[1:]:\n",
    "    ethnicity_df[column] = ethnicity_df[column].astype(int)\n",
    "\n",
    "# Sum duplicate rows since we consider regions of a City as the same City, and sort data by City\n",
    "ethnicity_df = ethnicity_df.groupby('City').sum().reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Surrogate Keys for Ethnicity Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not sure if this is needed since we can easily match through the natural keys\n",
    "ethnicity_df.insert(0, 'Ethnicity City ID', '')\n",
    "ethnicity_df['Ethnicity City ID'] = ['E' + str(x) for x in range(1, len(ethnicity_df) + 1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Facility Type Data Frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_facilities = df['FacilityType'].unique()\n",
    "\n",
    "facility_type_df = pd.DataFrame()\n",
    "facility_type_df['Facility Type ID'] = ['FT' + str(x) for x in range(1, len(unique_facilities) + 1)]\n",
    "facility_type_df['Type'] = unique_facilities"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Populate Facility Dataframe with Foreign Keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.merge(df, facility_type_df, left_on='FacilityType', right_on='Type', how='left')\n",
    "df = df.drop(columns = ['FacilityType', 'Type'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Mappings for Ethnicites and Age Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_mapping_df = pd.DataFrame()\n",
    "age_mapping_df['Age_ID'] = range(1,len(age_df.columns[2:])+1)\n",
    "age_mapping_df['Value'] = age_df.columns[2:]\n",
    "\n",
    "ethnicity_mapping_df = pd.DataFrame()\n",
    "ethnicity_mapping_df['Ethnicity_ID'] = range(1,len(ethnicity_df.columns[2:])+1)\n",
    "ethnicity_mapping_df['Value'] = ethnicity_df.columns[2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Generating Measure/Fact Table**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact_df = pd.DataFrame()\n",
    "fact_df['City'] = age_df['City']\n",
    "fact_df = fact_df.sort_values(by='City').reset_index(drop=True)\n",
    "fact_df['Age City ID'] = age_df['Age City ID']\n",
    "fact_df['Ethnicity City ID'] = ethnicity_df['Ethnicity City ID']\n",
    "fact_df['Facility Count'] = None\n",
    "fact_df['Highest Population Age ID'] = None\n",
    "fact_df['Highest Population Ethnicity ID'] = None\n",
    "\n",
    "\n",
    "for i in range(len(age_df)):\n",
    "    fact_df.loc[i, 'Highest Population Age ID'] = (age_df.iloc[i, 2:]).idxmax()\n",
    "    fact_df.loc[i, 'Highest Population Ethnicity ID'] = (ethnicity_df.iloc[i, 2:]).idxmax()\n",
    "    fact_df.loc[i, 'Facility Count'] = (df['City'] == fact_df.loc[i, 'City']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 403,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding all facility IDs that belong to a city\n",
    "merged_df = pd.merge(fact_df, df, left_on='City', right_on='City', how='left')\n",
    "\n",
    "# Group by City and aggregate values of Facility ID into a list\n",
    "result = merged_df.groupby('City')['Facility ID'].agg(list).reset_index()\n",
    "\n",
    "# Rename the aggregated column to the desired column name in DataFrame A\n",
    "result.rename(columns={'Facility ID': 'Facility IDs'}, inplace=True)\n",
    "\n",
    "# Merge the result back to DataFrame  on X\n",
    "fact_df = pd.merge(fact_df, result, on='City', how='left')\n",
    "\n",
    "df = df.drop(columns = ['City'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Update text value mappings with numeric values for measure data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_dict_age = dict(zip(age_mapping_df['Value'], age_mapping_df['Age_ID']))\n",
    "fact_df['Highest Population Age ID'] = fact_df['Highest Population Age ID'].map(mapping_dict_age)\n",
    "\n",
    "mapping_dict_ethnicity = dict(zip(ethnicity_mapping_df['Value'], ethnicity_mapping_df['Ethnicity_ID']))\n",
    "fact_df['Highest Population Ethnicity ID'] = fact_df['Highest Population Ethnicity ID'].map(mapping_dict_ethnicity)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('facility_df.csv', index=False)\n",
    "facility_type_df.to_csv('facility_type_df.csv', index=False)\n",
    "age_df.to_csv('age_df.csv', index=False)\n",
    "ethnicity_df.to_csv('eth_df.csv', index=False)\n",
    "fact_df.to_csv('fact_df.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "history_visible": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
